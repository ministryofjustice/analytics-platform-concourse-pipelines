---
jobs:
- name: lint
  plan:
  - get: resource-dags-pr
    trigger: true
    version: every
  - get: common-tasks
  - aggregate:
    - put: resource-dags-pr
      params:
        context: lint
        path: resource-dags-pr
        status: pending
    - put: resource-dags-pr
      params:
        context: list-roles
        path: resource-dags-pr
        status: pending
  - aggregate:
    - task: run-lint
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: quay.io/mojanalytics/airflow
            tag: 1.10.3
        params:
          AIRFLOW__CORE__DAGS_FOLDER: ./resource-dags-pr
          AIRFLOW__CORE__LOAD_EXAMPLES: "false"
        run:
          path: python
          args:
          - -c
          - |
            from airflow.models import DagBag
            import airflow.utils.dag_processing
            d = DagBag()
            assert len(d.import_errors) == 0, 'There should be no DAG failures. Got {}'.format(d.import_errors)
        inputs:
        - name: resource-dags-pr
    - task: list-roles-used-by-dags
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: quay.io/mojanalytics/airflow
            tag: 1.10.3
        params:
          AIRFLOW__CORE__DAGS_FOLDER: ./resource-dags-pr
          AIRFLOW__CORE__LOAD_EXAMPLES: "false"
        run:
          path: python
          args:
          - -c
          - |
            import itertools
            from airflow.models import DagBag
            import airflow.utils.dag_processing

            d = DagBag()

            all_tasks = itertools.chain.from_iterable(dag.tasks for dag in d.dags.values())
            annotated_tasks = [x for x in all_tasks if hasattr(x, 'annotations')]

            annotations = set(itertools.chain.from_iterable(t.annotations.values() for t in annotated_tasks if t.annotations))
            with open('dag-roles/roles.txt', 'w') as f:
              f.writelines([f'{role}\n' for role in annotations])
        inputs:
        - name: resource-dags-pr
        outputs:
        - name: dag-roles
    on_failure:
      put: resource-dags-pr
      params:
        context: list-roles
        path: resource-dags-pr
        status: failure
  - aggregate:
    - put: resource-dags-pr
      params:
        context: list-roles
        path: resource-dags-pr
        status: success
    - put: resource-dags-pr
      params:
        context: lint
        path: resource-dags-pr
        status: success
    - put: resource-dags-pr
      params:
        context: check-role-annotation
        path: resource-dags-pr
        status: pending
    - put: resource-dags-pr
      params:
        context: iam-policy-change
        path: resource-dags-pr
        status: pending
    - put: resource-dags-pr
      params:
        context: pep8
        path: resource-dags-pr
        status: pending
  - task: check-role-annotation
    config:
      platform: linux
      image_resource:
        type: docker-image
        source:
          repository: governmentpaas/awscli
          tag: latest
      params:
        AWS_ACCESS_KEY_ID: ((secrets.iam-list-roles-key-id))
        AWS_SECRET_ACCESS_KEY: ((secrets.iam-list-roles-secret-access-key))
      run:
        path: sh
        args:
        - -c
        - |
          aws iam list-roles | jq -r .Roles[].RoleName > dag-roles/aws.txt
          sort dag-roles/roles.txt -o dag-roles/roles.txt
          sort dag-roles/aws.txt -o dag-roles/aws.txt
          comm -23 dag-roles/roles.txt dag-roles/aws.txt > dag-roles/missing-from-aws.txt
          echo "#### annotated roles ###"
          cat dag-roles/roles.txt
          echo "### missing AWS IAM role(s) ###" > comment/comment.txt
          echo \`\`\` >> comment/comment.txt
          cat dag-roles/missing-from-aws.txt >> comment/comment.txt
          echo \`\`\` >> comment/comment.txt
          echo "⚠ ensure the roles ☝ are defined in the aws console ⚠" >> comment/comment.txt
          cat comment/comment.txt
          exit $(wc -l dag-roles/missing-from-aws.txt | awk '{print $1}')
      inputs:
      - name: resource-dags-pr
      - name: dag-roles
      outputs:
      - name: comment
    on_failure:
      put: resource-dags-pr
      params:
        comment_file: comment/comment.txt
        context: check-role-annotation
        path: resource-dags-pr
        status: failure
  - put: resource-dags-pr
    params:
      context: check-role-annotation
      path: resource-dags-pr
      status: success
  - task: git-list-updated-dags
    config:
      platform: linux
      image_resource:
        type: docker-image
        source:
          repository: quay.io/mojanalytics/alpine-python-git-jq
          tag: latest
      params:
        GITHUB_TOKEN: ((secrets.github-access-token))
      run:
        path: bash
        args:
        - -c
        - |
          git clone https://moj-analytical-services:$GITHUB_TOKEN@github.com/moj-analytical-services/airflow-dags.git
          cd $(pwd)/airflow-dags
          git fetch --all
          branch=$(cat $(pwd)/../resource-dags-pr/.git/resource/head_name)
          git checkout $branch
          git diff --name-only master | grep -v '/' | grep .py
          git diff --name-only master | grep -v '/' | grep .py > $(pwd)/../dag-list.txt
          cd $(pwd)/../
          echo 'Updated DAG files'
          echo __init__.py >> dag-list.txt
          cat dag-list.txt
          for dagfile in $(pwd)/airflow-dags/*.py; do
            if grep -q $(basename $dagfile) dag-list.txt; then
              echo \"Keeping: $(basename $dagfile)\"
            else
              echo \"REMOVING: $(basename $dagfile)\"
              rm -rf $dagfile
            fi
          done
      inputs:
      - name: resource-dags-pr
      outputs:
      - name: airflow-dags
  - task: list-images-used-by-updated-dags
    config:
      platform: linux
      image_resource:
        type: docker-image
        source:
          repository: quay.io/mojanalytics/airflow
          tag: 1.10.3
      params:
        AIRFLOW__CORE__DAGS_FOLDER: ./airflow-dags
        AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      run:
        path: python
        args:
        - -c
        - |
          import itertools
          from airflow.models import DagBag
          import airflow.utils.dag_processing

          d = DagBag()

          all_tasks = itertools.chain.from_iterable(dag.tasks for dag in d.dags.values())

          def si(image):
              return image.split('/')[1].split(':')[0]

          with open('repos/list.txt', 'w') as f:
              f.writelines(set([f'{si(task.image)}\n' for task in all_tasks if getattr(task, 'image', None) and 'amazonaws.com' in task.image]))
      inputs:
      - name: airflow-dags
      outputs:
      - name: repos
  - task: extract-policies-from-repos
    file: common-tasks/extract-policies-from-repos.yaml
  - try:
      task: check-iam-changes
      file: common-tasks/diff-iam-policy.yaml
      on_failure:
        put: resource-dags-pr
        params:
          context: iam-policy-change
          path: resource-dags-pr
          status: failure
      on_success:
        put: resource-dags-pr
        params:
          context: iam-policy-change
          path: resource-dags-pr
          status: success
  - try:
      task: pep8
      file: common-tasks/python-flake8.yaml
      input_mapping:
        source: resource-dags-pr
      on_failure:
        put: resource-dags-pr
        params:
          context: pep8
          path: resource-dags-pr
          status: failure
        attempts: 3
      on_success:
        put: resource-dags-pr
        params:
          context: pep8
          path: resource-dags-pr
          status: success
        attempts: 3

resource_types:
  - name: pull-request
    type: docker-image
    source:
      repository: teliaoss/github-pr-resource

resources:
- name: resource-dags-pr
  type: pull-request
  check_every: 10m
  webhook_token: ((secrets.github-webhook-token))
  source:
    repository: ((repo))
    access_token: ((secrets.github-access-token))
- name: common-tasks
  type: git
  source:
    uri: https://github.com/ministryofjustice/analytics-platform-common-concourse-tasks.git
